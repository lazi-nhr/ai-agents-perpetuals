{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1bb7b54",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Agent for Statistical Arbitrage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e79612d",
   "metadata": {},
   "source": [
    "## Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b434b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip -q install -U numpy pandas pyarrow gdown gymnasium stable-baselines3 torch matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4664e80a",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34fbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"DATA\": {\n",
    "        \"drive_folder_id\": \"1uXEBUyySypdsW_ZqL-RZ3d1bWdIZisij\",\n",
    "        \"structure\": {\"1d\":\"ohlcv_1d\",\"1h\":\"ohlcv_1h\",\"15m\":\"ohlcv_15m\",\"5m\":\"ohlcv_5m\",\"1m\":\"ohlcv_1m\"},\n",
    "        \"file_pattern\": \"{TICKER}_{FREQ}.parquet\",\n",
    "        \"tickers\": [\"BTC\",\"ETH\"],\n",
    "        \"sampling\": \"1h\",\n",
    "        \"price_point\": \"close\",\n",
    "        \"timezone_in\": \"CET\",\n",
    "        \"timezone_out\": \"UTC\",\n",
    "        \"forward_fill\": True,\n",
    "        \"drop_na_after_ffill\": True,\n",
    "        \"cache_dir\": \"./data_cache\",\n",
    "        \"DOWNLOAD\": {\n",
    "            \"method\": \"file_ids\",\n",
    "            \"file_ids\": {\"BTC_1h\": \"1-sBNQpEFGEpVO3GDFCkSZiV3Iaqp2vB_\", \"ETH_1h\": \"1kj8G1scpFuEYTTXKEUzF9pwgGI2WFFL9\"},\n",
    "            \"download_all\": False\n",
    "        }\n",
    "    },\n",
    "    \"ENV\": {\n",
    "        \"action_space\": \"continuous_weights\",\n",
    "        \"include_cash\": True,\n",
    "        \"shorting\": False,\n",
    "        \"max_leverage\": 1.0,\n",
    "        \"rebalance_interval\": \"1_bar\",\n",
    "        \"episode_length\": {\"mode\":\"steps\",\"value\":2160},\n",
    "        \"lookback_window\": 64,\n",
    "        \"features\": {\n",
    "            \"log_return_window\": 1,\n",
    "            \"vol_window\": 64,\n",
    "            \"rsi_period\": 14,\n",
    "            \"volume_change\": True,\n",
    "            \"scaler\": \"rolling_zscore\"\n",
    "        },\n",
    "        \"transaction_costs\": {\n",
    "            \"commission_bps\": 5.0,\n",
    "            \"slippage_bps\": 5.0,\n",
    "            \"apply_on_rebalance_only\": True\n",
    "        },\n",
    "        \"turnover_penalty\": 0.0,\n",
    "        \"weight_smoothing\": 0.0,\n",
    "        \"reward\": {\"type\":\"log_return_minus_risk\",\"risk_lambda\":0.001},\n",
    "        \"constraints\": {\"min_weight\":0.0,\"max_weight\":1.0,\"sum_to_one\":True},\n",
    "        \"seed\": 42\n",
    "    },\n",
    "    \"SPLITS\": {\n",
    "        \"data_start\":\"2024-09-02\",\n",
    "        \"data_end\":\"2025-09-02\",\n",
    "        \"train\":[\"2024-09-02\",\"2025-06-15\"],\n",
    "        \"val\":[\"2025-06-16\",\"2025-07-15\"],\n",
    "        \"test\":[\"2025-07-16\",\"2025-09-02\"],\n",
    "        \"walk_forward\": True,\n",
    "        \"wf_train_span_days\": 180,\n",
    "        \"wf_test_span_days\": 30,\n",
    "        \"wf_step_days\": 30\n",
    "    },\n",
    "    \"RL\": {\n",
    "        \"algo\":\"PPO\",\n",
    "        \"timesteps\":8_000_000,\n",
    "        \"device\":\"auto\",\n",
    "        \"policy\":\"MlpPolicy\",\n",
    "        \"gamma\":0.99,\n",
    "        \"gae_lambda\":0.95,\n",
    "        \"clip_range\":0.2,\n",
    "        \"n_steps\":2048,\n",
    "        \"batch_size\":8192,\n",
    "        \"learning_rate\":3e-4,\n",
    "        \"ent_coef\":0.0,\n",
    "        \"vf_coef\":0.5,\n",
    "        \"max_grad_norm\":0.5\n",
    "    },\n",
    "    \"EVAL\": {\n",
    "        \"benchmarks\":[\"equal_weight_hold\",\"buy_and_hold_BTC\",\"buy_and_hold_ETH\"],\n",
    "        \"metrics\":[\"CAGR\",\"Sharpe\",\"Sortino\",\"MaxDrawdown\",\"Calmar\",\"Volatility\",\"Turnover\",\"HitRatio\"],\n",
    "        \"plots\":True,\n",
    "        \"reports_dir\":\"./reports\"\n",
    "    },\n",
    "    \"IO\": {\n",
    "        \"models_dir\":\"./models\",\n",
    "        \"tb_logdir\":\"./tb\",\n",
    "        \"save_best_on_val\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568820c4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4143bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import gdown # download files from google drive\n",
    "import math\n",
    "import glob\n",
    "import random\n",
    "import pytz\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63981a61",
   "metadata": {},
   "source": [
    "## Set Seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775695a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "set_all_seeds(CONFIG[\"ENV\"][\"seed\"])\n",
    "\n",
    "ANNUALIZATION = {\"1m\":365*24*60,\"5m\":365*24*12,\"15m\":365*24*4,\"1h\":365*24,\"1d\":365}\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b556fc3",
   "metadata": {},
   "source": [
    "## Fetch Data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e7db74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File BTC_1h already exists in cache. Skipping download.\n",
      "File ETH_1h already exists in cache. Skipping download.\n",
      "Download step complete.\n"
     ]
    }
   ],
   "source": [
    "ROOT_ID = CONFIG[\"DATA\"][\"drive_folder_id\"]\n",
    "CACHE_DIR = CONFIG[\"DATA\"][\"cache_dir\"]\n",
    "ensure_dir(CACHE_DIR)\n",
    "\n",
    "def download_drive_folder(root_id: str, out_dir: str):\n",
    "    print(\"Mirroring Google Drive folder locally...\")\n",
    "    gdown.download_folder(id=root_id, output=out_dir, quiet=False, use_cookies=False)\n",
    "\n",
    "def targeted_download_by_ids(file_id_map: Dict[str, str], out_dir: str):\n",
    "    ensure_dir(out_dir)\n",
    "    for name, fid in file_id_map.items():\n",
    "        # check if file already exist in cache\n",
    "        if os.path.exists(os.path.join(out_dir, name)) or os.path.exists(os.path.join(out_dir, f\"{name}.parquet\")):\n",
    "            print(f\"File {name} already exists in cache. Skipping download.\")\n",
    "            continue\n",
    "        \n",
    "        suffix = name if name.endswith(\".parquet\") else f\"{name}.parquet\"\n",
    "        out_path = os.path.join(out_dir, suffix)\n",
    "        print(f\"Downloading {name} -> {out_path}\")\n",
    "        url = f\"https://drive.google.com/uc?id={fid}\"\n",
    "        gdown.download(url, out_path, quiet=False, use_cookies=False)\n",
    "\n",
    "download_method = CONFIG[\"DATA\"][\"DOWNLOAD\"][\"method\"]\n",
    "if download_method == \"file_ids\" and CONFIG[\"DATA\"][\"DOWNLOAD\"][\"file_ids\"]:\n",
    "    targeted_download_by_ids(CONFIG[\"DATA\"][\"DOWNLOAD\"][\"file_ids\"], CACHE_DIR)\n",
    "else:\n",
    "    download_drive_folder(ROOT_ID, CACHE_DIR)\n",
    "\n",
    "print(\"Download step complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151dd54",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1c9541d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BTC': (8785, 5), 'ETH': (8785, 5)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-09-02 18:00:00</th>\n",
       "      <td>110914.01</td>\n",
       "      <td>110945.30</td>\n",
       "      <td>110200.00</td>\n",
       "      <td>110646.47</td>\n",
       "      <td>506.68111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02 19:00:00</th>\n",
       "      <td>110646.47</td>\n",
       "      <td>110840.00</td>\n",
       "      <td>110441.42</td>\n",
       "      <td>110806.00</td>\n",
       "      <td>447.85722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02 20:00:00</th>\n",
       "      <td>110806.01</td>\n",
       "      <td>111419.18</td>\n",
       "      <td>110716.77</td>\n",
       "      <td>111418.49</td>\n",
       "      <td>585.42846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02 21:00:00</th>\n",
       "      <td>111418.49</td>\n",
       "      <td>111538.17</td>\n",
       "      <td>111129.57</td>\n",
       "      <td>111129.57</td>\n",
       "      <td>356.26128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-02 22:00:00</th>\n",
       "      <td>111129.58</td>\n",
       "      <td>111240.00</td>\n",
       "      <td>110870.27</td>\n",
       "      <td>111193.34</td>\n",
       "      <td>362.08816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          open       high        low      close     volume\n",
       "datetime                                                                  \n",
       "2025-09-02 18:00:00  110914.01  110945.30  110200.00  110646.47  506.68111\n",
       "2025-09-02 19:00:00  110646.47  110840.00  110441.42  110806.00  447.85722\n",
       "2025-09-02 20:00:00  110806.01  111419.18  110716.77  111418.49  585.42846\n",
       "2025-09-02 21:00:00  111418.49  111538.17  111129.57  111129.57  356.26128\n",
       "2025-09-02 22:00:00  111129.58  111240.00  110870.27  111193.34  362.08816"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling = CONFIG[\"DATA\"][\"sampling\"]\n",
    "subfolder = CONFIG[\"DATA\"][\"structure\"][sampling]\n",
    "pattern_fmt = CONFIG[\"DATA\"][\"file_pattern\"]\n",
    "tickers = CONFIG[\"DATA\"][\"tickers\"]\n",
    "\n",
    "# Function to find parquet file path\n",
    "def find_parquet_path(ticker: str, sampling: str) -> str:\n",
    "    fname = pattern_fmt.format(TICKER=ticker, FREQ=sampling)\n",
    "    # Try subfolder first\n",
    "    candidates = glob.glob(os.path.join(CACHE_DIR, \"**\", subfolder, fname), recursive=True)\n",
    "    # If not found, try flat cache\n",
    "    if not candidates:\n",
    "        candidates = glob.glob(os.path.join(CACHE_DIR, \"**\", fname), recursive=True)\n",
    "    # If still not found, try direct file in cache (for file_ids downloads)\n",
    "    if not candidates:\n",
    "        direct_path = os.path.join(CACHE_DIR, fname)\n",
    "        if os.path.exists(direct_path):\n",
    "            candidates = [direct_path]\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"Could not find {fname} under {CACHE_DIR}.\")\n",
    "    return candidates[0]\n",
    "\n",
    "def localize_and_align(df: pd.DataFrame, tz_in: str = None, tz_out: str = None) -> pd.DataFrame:\n",
    "    if 'datetime' in df.columns:\n",
    "        # Convert millisecond timestamps to datetime\n",
    "        df['timestamp'] = pd.to_datetime(df['datetime'], unit='ms', utc=True)\n",
    "        df = df.set_index('timestamp')\n",
    "    # Make column names lowercase\n",
    "    cols = {c: c.lower() for c in df.columns}\n",
    "    df = df.rename(columns=cols)\n",
    "    return df.sort_index()\n",
    "\n",
    "dfs = {}\n",
    "for t in tickers:\n",
    "    pth = find_parquet_path(t, sampling)\n",
    "    tmp = pd.read_parquet(pth)\n",
    "    tmp = localize_and_align(tmp)  # No need to pass timezone parameters\n",
    "    if CONFIG[\"DATA\"][\"forward_fill\"]:\n",
    "        tmp = tmp.ffill()\n",
    "    if CONFIG[\"DATA\"][\"drop_na_after_ffill\"]:\n",
    "        tmp = tmp.dropna()\n",
    "    dfs[t] = tmp\n",
    "\n",
    "common_index = None\n",
    "for t, df in dfs.items():\n",
    "    common_index = df.index if common_index is None else common_index.intersection(df.index)\n",
    "for t in tickers:\n",
    "    dfs[t] = dfs[t].reindex(common_index).dropna()\n",
    "\n",
    "print({t: dfs[t].shape for t in tickers})\n",
    "dfs[\"BTC\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a77e6",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b326bc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker                    BTC                                      ETH  \\\n",
      "feature                   ret       vol        rsi    volchg       ret   \n",
      "datetime                                                                 \n",
      "2025-09-02 18:00:00 -0.002415  0.004553  56.046963 -0.326068 -0.005253   \n",
      "2025-09-02 19:00:00  0.001441  0.004556  57.347919 -0.123407 -0.005208   \n",
      "2025-09-02 20:00:00  0.005512  0.004575  61.998583  0.267870  0.009015   \n",
      "2025-09-02 21:00:00 -0.002596  0.004589  58.744666 -0.496680  0.003603   \n",
      "2025-09-02 22:00:00  0.000574  0.004588  59.252994  0.016223 -0.000814   \n",
      "\n",
      "ticker                                              \n",
      "feature                   vol        rsi    volchg  \n",
      "datetime                                            \n",
      "2025-09-02 18:00:00  0.006955  43.078511  0.493765  \n",
      "2025-09-02 19:00:00  0.006879  40.698143 -0.197759  \n",
      "2025-09-02 20:00:00  0.006964  46.245797 -0.063885  \n",
      "2025-09-02 21:00:00  0.006982  48.339198 -0.467361  \n",
      "2025-09-02 22:00:00  0.006952  47.885173  0.147730  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BTC</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ETH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>ret</th>\n",
       "      <th>vol</th>\n",
       "      <th>rsi</th>\n",
       "      <th>volchg</th>\n",
       "      <th>ret</th>\n",
       "      <th>vol</th>\n",
       "      <th>rsi</th>\n",
       "      <th>volchg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "      <td>8784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>51.232259</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>51.206699</td>\n",
       "      <td>-0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>11.619616</td>\n",
       "      <td>0.528632</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.002781</td>\n",
       "      <td>12.326999</td>\n",
       "      <td>0.546888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.050195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.149282</td>\n",
       "      <td>-0.124892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.828906</td>\n",
       "      <td>-2.068495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.002048</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>43.736511</td>\n",
       "      <td>-0.347504</td>\n",
       "      <td>-0.003253</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>43.299516</td>\n",
       "      <td>-0.360170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>51.268990</td>\n",
       "      <td>-0.024810</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.006657</td>\n",
       "      <td>51.018342</td>\n",
       "      <td>-0.043595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>58.885158</td>\n",
       "      <td>0.296147</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>58.761127</td>\n",
       "      <td>0.317103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.049047</td>\n",
       "      <td>0.013790</td>\n",
       "      <td>90.153680</td>\n",
       "      <td>2.690468</td>\n",
       "      <td>0.091261</td>\n",
       "      <td>0.022406</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.696904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker           BTC                                                 ETH  \\\n",
       "feature          ret          vol          rsi       volchg          ret   \n",
       "count    8784.000000  8784.000000  8784.000000  8784.000000  8784.000000   \n",
       "mean        0.000075     0.004585    51.232259    -0.000192     0.000067   \n",
       "std         0.004991     0.001950    11.619616     0.528632     0.007677   \n",
       "min        -0.050195     0.000000     0.000000    -2.149282    -0.124892   \n",
       "25%        -0.002048     0.003331    43.736511    -0.347504    -0.003253   \n",
       "50%         0.000064     0.004109    51.268990    -0.024810     0.000131   \n",
       "75%         0.002256     0.005470    58.885158     0.296147     0.003631   \n",
       "max         0.049047     0.013790    90.153680     2.690468     0.091261   \n",
       "\n",
       "ticker                                          \n",
       "feature          vol          rsi       volchg  \n",
       "count    8784.000000  8784.000000  8784.000000  \n",
       "mean        0.007127    51.206699    -0.000106  \n",
       "std         0.002781    12.326999     0.546888  \n",
       "min         0.000000     6.828906    -2.068495  \n",
       "25%         0.005369    43.299516    -0.360170  \n",
       "50%         0.006657    51.018342    -0.043595  \n",
       "75%         0.008315    58.761127     0.317103  \n",
       "max         0.022406   100.000000     2.696904  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_rsi(series: pd.Series, period: int = 14) -> pd.Series:\n",
    "    delta = series.diff()\n",
    "    up = (delta.clip(lower=0)).ewm(alpha=1/period, adjust=False).mean()\n",
    "    down = (-delta.clip(upper=0)).ewm(alpha=1/period, adjust=False).mean()\n",
    "    rs = up / (down + 1e-12)\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def make_features(df: pd.DataFrame, price_col: str, vol_window: int, rsi_period: int, volume_change: bool):\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    out[\"ret\"] = np.log(df[price_col]).diff(1)\n",
    "    out[\"vol\"] = out[\"ret\"].rolling(vol_window).std().fillna(0.0)\n",
    "    out[\"rsi\"] = compute_rsi(df[price_col], rsi_period).fillna(50.0)\n",
    "    if \"volume\" in df.columns and volume_change:\n",
    "        out[\"volchg\"] = np.log(df[\"volume\"].replace(0, np.nan)).diff().fillna(0.0)\n",
    "    else:\n",
    "        out[\"volchg\"] = 0.0\n",
    "    return out\n",
    "\n",
    "feat_cfg = CONFIG[\"ENV\"][\"features\"]\n",
    "lookback = CONFIG[\"ENV\"][\"lookback_window\"]\n",
    "price_col = CONFIG[\"DATA\"][\"price_point\"]\n",
    "\n",
    "features_by_ticker = {}\n",
    "for t in tickers:\n",
    "    fdf = make_features(dfs[t], price_col, feat_cfg[\"vol_window\"], feat_cfg[\"rsi_period\"], feat_cfg[\"volume_change\"])\n",
    "    features_by_ticker[t] = fdf\n",
    "\n",
    "panel_cols = []\n",
    "for t in tickers:\n",
    "    for col in [\"ret\",\"vol\",\"rsi\",\"volchg\"]:\n",
    "        panel_cols.append((t, col))\n",
    "panel = pd.concat([features_by_ticker[t][[\"ret\",\"vol\",\"rsi\",\"volchg\"]] for t in tickers], axis=1)\n",
    "panel.columns = pd.MultiIndex.from_tuples(panel_cols, names=[\"ticker\",\"feature\"])\n",
    "panel = panel.dropna()\n",
    "\n",
    "print(panel.tail())\n",
    "panel.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da1a418",
   "metadata": {},
   "source": [
    "## Feature scaling and state tensor construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f681542d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/5j76lpw55lb8_mzj13c6_ls00000gn/T/ipykernel_2717/3295769342.py:9: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  scaled = panel.groupby(level=1, axis=1).apply(lambda g: rolling_zscore(g, window=max(lookback*2, 256)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State tensor: (8719, 2, 4, 64) Returns: (8719, 2) InstVol: (8719, 2)\n"
     ]
    }
   ],
   "source": [
    "def rolling_zscore(df: pd.DataFrame, window: int = 256) -> pd.DataFrame:\n",
    "    mu = df.rolling(window).mean()\n",
    "    sigma = df.rolling(window).std().replace(0, np.nan)\n",
    "    z = (df - mu) / (sigma + 1e-12)\n",
    "    return z.fillna(0.0)\n",
    "\n",
    "def build_state_tensor(panel: pd.DataFrame, lookback: int, scaler: str = \"rolling_zscore\"):\n",
    "    if scaler == \"rolling_zscore\":\n",
    "        scaled = panel.groupby(level=1, axis=1).apply(lambda g: rolling_zscore(g, window=max(lookback*2, 256)))\n",
    "        scaled.columns = panel.columns\n",
    "    else:\n",
    "        scaled = panel.copy()\n",
    "\n",
    "    tickers = sorted({c[0] for c in scaled.columns})\n",
    "    features = sorted({c[1] for c in scaled.columns})\n",
    "    times = scaled.index\n",
    "\n",
    "    X, y_ret, inst_vol = [], [], []\n",
    "    for i in range(lookback, len(times)-1):\n",
    "        window_slice = scaled.iloc[i-lookback:i]\n",
    "        frames = []\n",
    "        for t in tickers:\n",
    "            frames.append(window_slice[t].T.values)\n",
    "        tensor = np.stack(frames, axis=0)\n",
    "        X.append(tensor)\n",
    "        nxt = panel.iloc[i+1]\n",
    "        y_ret.append(np.array([nxt[(t, \"ret\")] for t in tickers], dtype=float))\n",
    "        cur = panel.iloc[i]\n",
    "        inst_vol.append(np.array([cur[(t, \"vol\")] for t in tickers], dtype=float))\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y_ret = np.array(y_ret, dtype=np.float32)\n",
    "    inst_vol = np.array(inst_vol, dtype=np.float32)\n",
    "    return X, y_ret, inst_vol, tickers, features, times[lookback+1:]\n",
    "\n",
    "X_all, R_all, VOL_all, TICKER_ORDER, FEAT_ORDER, TIME_INDEX = build_state_tensor(\n",
    "    panel, lookback=CONFIG[\"ENV\"][\"lookback_window\"], scaler=CONFIG[\"ENV\"][\"features\"][\"scaler\"]\n",
    ")\n",
    "print(\"State tensor:\", X_all.shape, \"Returns:\", R_all.shape, \"InstVol:\", VOL_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6a8a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 6 split(s). Example: WF_20240902_20250331\n"
     ]
    }
   ],
   "source": [
    "def date_slice_mask(times: pd.DatetimeIndex, start: str, end: str):\n",
    "    # Convert string dates to UTC timestamps\n",
    "    start_ts = pd.Timestamp(start).tz_localize('UTC')\n",
    "    end_ts = pd.Timestamp(end).tz_localize('UTC')\n",
    "    \n",
    "    # Ensure times are in UTC\n",
    "    if times.tz is None:\n",
    "        times = times.tz_localize('UTC')\n",
    "    elif times.tz != pytz.UTC:\n",
    "        times = times.tz_convert('UTC')\n",
    "        \n",
    "    return (times >= start_ts) & (times <= end_ts)\n",
    "\n",
    "def build_splits(times: pd.DatetimeIndex, cfg: dict):\n",
    "    s = CONFIG[\"SPLITS\"]\n",
    "    \n",
    "    # Ensure times are in UTC\n",
    "    if times.tz is None:\n",
    "        times = times.tz_localize('UTC')\n",
    "    elif times.tz != pytz.UTC:\n",
    "        times = times.tz_convert('UTC')\n",
    "        \n",
    "    if not s[\"walk_forward\"]:\n",
    "        m_train = date_slice_mask(times, s[\"train\"][0], s[\"train\"][1])\n",
    "        m_val   = date_slice_mask(times, s[\"val\"][0], s[\"val\"][1])\n",
    "        m_test  = date_slice_mask(times, s[\"test\"][0], s[\"test\"][1])\n",
    "        return [{\"name\":\"BaseSplit\",\"train\":m_train,\"val\":m_val,\"test\":m_test}]\n",
    "    else:\n",
    "        # Create timezone-aware timestamps for start/end\n",
    "        start = pd.Timestamp(s[\"data_start\"]).tz_localize('UTC')\n",
    "        end   = pd.Timestamp(s[\"data_end\"]).tz_localize('UTC')\n",
    "        spans = []\n",
    "        cur_train_start = start\n",
    "        while True:\n",
    "            train_end = cur_train_start + timedelta(days=s[\"wf_train_span_days\"])\n",
    "            test_end  = train_end + timedelta(days=s[\"wf_test_span_days\"])\n",
    "            if test_end > end:\n",
    "                break\n",
    "            m_train = (times >= cur_train_start) & (times <= train_end)\n",
    "            m_val   = (times > train_end) & (times <= train_end)\n",
    "            m_test  = (times > train_end) & (times <= test_end)\n",
    "            spans.append({\n",
    "                \"name\": f\"WF_{cur_train_start.strftime('%Y%m%d')}_{test_end.strftime('%Y%m%d')}\",\n",
    "                \"train\": m_train,\n",
    "                \"val\": m_val,\n",
    "                \"test\": m_test\n",
    "            })\n",
    "            cur_train_start = cur_train_start + timedelta(days=s[\"wf_step_days\"])\n",
    "        return spans\n",
    "\n",
    "SPLITS = build_splits(TIME_INDEX, CONFIG[\"SPLITS\"])\n",
    "print(f\"Built {len(SPLITS)} split(s). Example:\", SPLITS[0][\"name\"] if SPLITS else \"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55aab18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PortfolioWeightsEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(self, X, R, VOL, tickers, lookback, cfg_env, sampling=\"1h\"):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.R = R\n",
    "        self.VOL = VOL\n",
    "        self.tickers = tickers\n",
    "        self.lookback = lookback\n",
    "        self.cfg = cfg_env\n",
    "        self.sampling = sampling\n",
    "\n",
    "        self.n_assets = len(tickers)\n",
    "        self.include_cash = cfg_env[\"include_cash\"]\n",
    "        self.dim_action = self.n_assets + (1 if self.include_cash else 0)\n",
    "\n",
    "        obs_dim = self.n_assets * self.X.shape[2] * self.lookback\n",
    "        self.observation_space = spaces.Box(low=-10, high=10, shape=(obs_dim,), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.dim_action,), dtype=np.float32)\n",
    "\n",
    "        self.commission = cfg_env[\"transaction_costs\"][\"commission_bps\"] / 1e4\n",
    "        self.slippage = cfg_env[\"transaction_costs\"][\"slippage_bps\"] / 1e4\n",
    "        self.apply_on_rebalance_only = cfg_env[\"transaction_costs\"][\"apply_on_rebalance_only\"]\n",
    "        self.risk_lambda = cfg_env[\"reward\"][\"risk_lambda\"]\n",
    "\n",
    "        self.min_w = cfg_env[\"constraints\"][\"min_weight\"]\n",
    "        self.max_w = cfg_env[\"constraints\"][\"max_weight\"]\n",
    "        self.sum_to_one = cfg_env[\"constraints\"][\"sum_to_one\"]\n",
    "\n",
    "        self.reset(seed=cfg_env.get(\"seed\", 42))\n",
    "\n",
    "    def _to_obs(self, t):\n",
    "        arr = self.X[t].reshape(-1).astype(np.float32)\n",
    "        return arr\n",
    "\n",
    "    def _project_weights(self, a):\n",
    "        if self.sum_to_one:\n",
    "            expo = np.exp(a - np.max(a))\n",
    "            w = expo / np.sum(expo)\n",
    "        else:\n",
    "            w = np.clip(a, self.min_w, self.max_w)\n",
    "        if not self.cfg[\"shorting\"]:\n",
    "            w = np.clip(w, 0.0, 1.0)\n",
    "        return w\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.t = 0\n",
    "        self.portfolio_value = 1.0\n",
    "        self.w = np.ones(self.dim_action) / self.dim_action\n",
    "        obs = self._to_obs(self.t)\n",
    "        return obs, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        w_target = self._project_weights(action)\n",
    "        turnover = np.sum(np.abs(w_target - self.w))\n",
    "        trading_cost = (self.commission + self.slippage) * turnover\n",
    "\n",
    "        asset_w_prev = self.w[:self.n_assets]\n",
    "        asset_ret = np.dot(asset_w_prev, self.R[self.t])\n",
    "        inst_vol = np.dot(asset_w_prev, self.VOL[self.t])\n",
    "\n",
    "        reward = asset_ret - trading_cost - self.risk_lambda * inst_vol\n",
    "\n",
    "        self.portfolio_value *= math.exp(asset_ret - trading_cost)\n",
    "\n",
    "        self.w = w_target\n",
    "        self.t += 1\n",
    "        terminated = (self.t >= len(self.R)-1)\n",
    "        truncated = False\n",
    "\n",
    "        obs = self._to_obs(self.t) if not terminated else self._to_obs(self.t-1)\n",
    "        info = {\"portfolio_value\": self.portfolio_value, \"turnover\": turnover, \"inst_vol\": inst_vol, \"asset_ret\": asset_ret}\n",
    "        return obs, reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7281e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env factory ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def slice_by_mask(X, R, VOL, mask: np.ndarray):\n",
    "    idx = np.where(mask)[0]\n",
    "    return X[idx], R[idx], VOL[idx]\n",
    "\n",
    "def make_env_from_mask(mask, name=\"env\"):\n",
    "    X_s, R_s, V_s = slice_by_mask(X_all, R_all, VOL_all, mask)\n",
    "    env = PortfolioWeightsEnv(X_s, R_s, V_s, TICKER_ORDER, CONFIG[\"ENV\"][\"lookback_window\"], CONFIG[\"ENV\"], sampling=CONFIG[\"DATA\"][\"sampling\"])\n",
    "    env = Monitor(env, filename=None)\n",
    "    return env\n",
    "\n",
    "print(\"Env factory ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dadc07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def annualize_factor(sampling: str):\n",
    "    return ANNUALIZATION.get(sampling, 365*24)\n",
    "\n",
    "def compute_metrics(equity_curve: pd.Series, sampling: str, turnover_series: pd.Series = None):\n",
    "    ret = equity_curve.pct_change().dropna()\n",
    "    ann = annualize_factor(sampling)\n",
    "    mu = ret.mean() * ann\n",
    "    sigma = ret.std() * math.sqrt(ann)\n",
    "    sharpe = mu / (sigma + 1e-12)\n",
    "    downside = ret[ret < 0].std() * math.sqrt(ann)\n",
    "    sortino = mu / (downside + 1e-12)\n",
    "    if len(equity_curve) > 1:\n",
    "        dt_years = (equity_curve.index[-1] - equity_curve.index[0]) / pd.Timedelta(days=365)\n",
    "        dt_years = float(dt_years) if float(dt_years) != 0 else 1e-12\n",
    "        cagr = (equity_curve.iloc[-1] / equity_curve.iloc[0]) ** (1/dt_years) - 1\n",
    "    else:\n",
    "        cagr = 0.0\n",
    "    cummax = equity_curve.cummax()\n",
    "    dd = (equity_curve / cummax - 1).min()\n",
    "    maxdd = float(dd)\n",
    "    calmar = mu / (abs(maxdd) + 1e-12)\n",
    "    hit_ratio = (ret > 0).mean()\n",
    "    turnover = turnover_series.mean() if turnover_series is not None and len(turnover_series)>0 else np.nan\n",
    "    return {\"CAGR\": cagr, \"Sharpe\": sharpe, \"Sortino\": sortino, \"MaxDrawdown\": maxdd, \"Calmar\": calmar, \"Volatility\": sigma, \"Turnover\": turnover, \"HitRatio\": hit_ratio}\n",
    "\n",
    "def plot_series(series: pd.Series, title: str):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(series.index, series.values)\n",
    "    plt.title(title); plt.xlabel(\"Time\"); plt.ylabel(\"Value\"); plt.show()\n",
    "\n",
    "def backtest_env(env: PortfolioWeightsEnv, model=None):\n",
    "    obs, _ = env.reset()\n",
    "    pv, turns = [], []\n",
    "    for t in range(len(env.R)-1):\n",
    "        if model is None:\n",
    "            action = np.ones(env.dim_action)/env.dim_action\n",
    "        else:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, trunc, info = env.step(action)\n",
    "        pv.append(info[\"portfolio_value\"])\n",
    "        turns.append(info[\"turnover\"])\n",
    "        if done:\n",
    "            break\n",
    "    idx = pd.RangeIndex(start=0, stop=len(pv), step=1)\n",
    "    ec = pd.Series(pv, index=idx)\n",
    "    to = pd.Series(turns, index=idx)\n",
    "    return ec, to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensure_dir(CONFIG[\"IO\"][\"models_dir\"])\n",
    "ensure_dir(CONFIG[\"EVAL\"][\"reports_dir\"])\n",
    "\n",
    "RESULTS = []\n",
    "\n",
    "for split in SPLITS:\n",
    "    print(f\"\\n=== Training on split: {split['name']} ===\")\n",
    "    train_env = make_env_from_mask(split[\"train\"], name=f\"{split['name']}_train\")\n",
    "    eval_env  = make_env_from_mask(split[\"test\"], name=f\"{split['name']}_test\")\n",
    "\n",
    "    vec_train = DummyVecEnv([lambda: train_env])\n",
    "    vec_eval  = DummyVecEnv([lambda: eval_env])\n",
    "\n",
    "    model = PPO(\n",
    "        policy=CONFIG[\"RL\"][\"policy\"],\n",
    "        env=vec_train,\n",
    "        gamma=CONFIG[\"RL\"][\"gamma\"],\n",
    "        gae_lambda=CONFIG[\"RL\"][\"gae_lambda\"],\n",
    "        clip_range=CONFIG[\"RL\"][\"clip_range\"],\n",
    "        n_steps=CONFIG[\"RL\"][\"n_steps\"],\n",
    "        batch_size=CONFIG[\"RL\"][\"batch_size\"],\n",
    "        learning_rate=CONFIG[\"RL\"][\"learning_rate\"],\n",
    "        ent_coef=CONFIG[\"RL\"][\"ent_coef\"],\n",
    "        vf_coef=CONFIG[\"RL\"][\"vf_coef\"],\n",
    "        max_grad_norm=CONFIG[\"RL\"][\"max_grad_norm\"],\n",
    "        tensorboard_log=CONFIG[\"IO\"][\"tb_logdir\"],\n",
    "        device=CONFIG[\"RL\"][\"device\"],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    eval_callback = EvalCallback(vec_eval, best_model_save_path=CONFIG[\"IO\"][\"models_dir\"],\n",
    "                                 log_path=CONFIG[\"IO\"][\"models_dir\"], eval_freq=10000,\n",
    "                                 deterministic=True, render=False)\n",
    "    model.learn(total_timesteps=CONFIG[\"RL\"][\"timesteps\"], callback=eval_callback)\n",
    "    model_path = os.path.join(CONFIG[\"IO\"][\"models_dir\"], f\"ppo_{split['name']}.zip\")\n",
    "    model.save(model_path)\n",
    "    print(\"Saved model:\", model_path)\n",
    "\n",
    "    test_env = make_env_from_mask(split[\"test\"], name=f\"{split['name']}_test\")\n",
    "    ec, to = backtest_env(test_env, model=model)\n",
    "\n",
    "    idx = np.where(split[\"test\"])[0]\n",
    "    R_test = R_all[idx]\n",
    "    ew = np.ones(len(TICKER_ORDER))/len(TICKER_ORDER)\n",
    "    ec_bench = [1.0]\n",
    "    for r in R_test[:-1]:\n",
    "        ec_bench.append(ec_bench[-1]*math.exp(np.dot(ew, r)))\n",
    "    ec_bench = pd.Series(ec_bench, index=ec.index)\n",
    "\n",
    "    bh_btc, bh_eth = [1.0], [1.0]\n",
    "    for r in R_test[:-1]:\n",
    "        bh_btc.append(bh_btc[-1]*math.exp(r[0]))\n",
    "        bh_eth.append(bh_eth[-1]*math.exp(r[1]))\n",
    "    bh_btc = pd.Series(bh_btc, index=ec.index)\n",
    "    bh_eth = pd.Series(bh_eth, index=ec.index)\n",
    "\n",
    "    m_model = compute_metrics(ec, CONFIG[\"DATA\"][\"sampling\"], to)\n",
    "    m_ew    = compute_metrics(ec_bench, CONFIG[\"DATA\"][\"sampling\"])\n",
    "    m_btc   = compute_metrics(bh_btc, CONFIG[\"DATA\"][\"sampling\"])\n",
    "    m_eth   = compute_metrics(bh_eth, CONFIG[\"DATA\"][\"sampling\"])\n",
    "\n",
    "    RESULTS.append({\"split\": split[\"name\"], \"model\": m_model, \"equal_weight\": m_ew, \"buy_and_hold_BTC\": m_btc, \"buy_and_hold_ETH\": m_eth})\n",
    "\n",
    "    if CONFIG[\"EVAL\"][\"plots\"]:\n",
    "        plot_series(ec, f\"Equity Curve — PPO ({split['name']})\")\n",
    "        plot_series((ec / ec.cummax()) - 1.0, f\"Drawdown — PPO ({split['name']})\")\n",
    "        plot_series(ec_bench, f\"Equity Curve — Equal-Weight Hold ({split['name']})\")\n",
    "\n",
    "print(\"Done. RESULTS collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for res in RESULTS:\n",
    "    row = {\"split\": res[\"split\"]}\n",
    "    for k, metrics in res.items():\n",
    "        if k == \"split\":\n",
    "            continue\n",
    "        for mname, mval in metrics.items():\n",
    "            row[f\"{k}_{mname}\"] = mval\n",
    "    rows.append(row)\n",
    "\n",
    "df_results = pd.DataFrame(rows)\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f15943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ensure_dir(CONFIG[\"EVAL\"][\"reports_dir\"])\n",
    "out_json = os.path.join(CONFIG[\"EVAL\"][\"reports_dir\"], f\"metrics_{ts}.json\")\n",
    "out_csv  = os.path.join(CONFIG[\"EVAL\"][\"reports_dir\"], f\"metrics_{ts}.csv\")\n",
    "df_results.to_csv(out_csv, index=False)\n",
    "with open(out_json, \"w\") as f:\n",
    "    json.dump(RESULTS, f, indent=2)\n",
    "print(\"Saved:\", out_json, \"and\", out_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2a785",
   "metadata": {},
   "source": [
    "**Notes:** Adjust fees for Hyperliquid; consider a separate validation set; extend features and risk controls as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
